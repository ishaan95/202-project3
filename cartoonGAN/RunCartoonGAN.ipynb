{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RunCartoonGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julinas/202-project3/blob/scene/cartoonGAN/RunCartoonGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Mkl_CrK731pf",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "5a996af5-0f0e-4f12-ded3-4016649c6bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "#@title mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-Pjvgu2a5xi",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "47558b55-f663-4a0b-cd54-6fd66acc7c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#@title cd to project3 folder\n",
        "%cd 'drive/My Drive/Colab Notebooks/project3'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/project3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1hvdynmmDmm3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title pytorch version run test\n",
        "# import torch\n",
        "# !python test.py --input_dir \"../sample\" --output_dir \"../sample_out\" --style Hosoda --gpu 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLm5_WJReeUV",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "494734b8-11f2-460b-daa9-dab78f8873da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#@title imports \n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Flatten, Dense, BatchNormalization, ReLU, Add, LeakyReLU\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "from keras import Model\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eAjxWGnSegps",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def make_generator (use: generator = make_generator())\n",
        "\n",
        "def make_generator():\n",
        "  in_ = Input(shape=(256, 256, 3))\n",
        "  conv1 = Conv2D(64, 7, padding=\"same\")(in_)\n",
        "  norm1 = BatchNormalization(epsilon=1e-9)(conv1)\n",
        "  relu1 = ReLU()(norm1)\n",
        "\n",
        "  # Down-convolution\n",
        "  conv2 = Conv2D(128, 3, padding=\"same\", strides=(2, 2))(relu1)\n",
        "  conv3 = Conv2D(128, 3, padding=\"same\")(conv2)\n",
        "  norm2 = BatchNormalization(epsilon=1e-9)(conv3)\n",
        "  relu2 = ReLU()(norm2)\n",
        "\n",
        "  conv4 = Conv2D(256, 3, padding=\"same\", strides=(2, 2))(relu2)\n",
        "  conv5 = Conv2D(256, 3, padding=\"same\")(conv4)\n",
        "  norm3 = BatchNormalization(epsilon=1e-9)(conv5)\n",
        "  relu3 = ReLU()(norm3)\n",
        "\n",
        "  # 8 residual blocks\n",
        "  # block_1\n",
        "  res_conv1_1 = Conv2D(256, 3, padding=\"same\")(relu3)\n",
        "  res_norm_1 = BatchNormalization(epsilon=1e-9)(res_conv1_1)\n",
        "  res_relu_1 = ReLU()(res_norm_1)\n",
        "  res_conv2_1 = Conv2D(256, 3, padding=\"same\")(res_relu_1)\n",
        "  res_norm2_1 = BatchNormalization(epsilon=1e-9)(res_conv2_1)\n",
        "  res_add_1 = Add()([relu3, res_norm2_1])\n",
        "\n",
        "  # block_2\n",
        "  res_conv1_2 = Conv2D(256, 3, padding=\"same\")(res_add_1)\n",
        "  res_norm_2 = BatchNormalization(epsilon=1e-9)(res_conv1_2)\n",
        "  res_relu_2 = ReLU()(res_norm_2)\n",
        "  res_conv2_2 = Conv2D(256, 3, padding=\"same\")(res_relu_2)\n",
        "  res_norm2_2 = BatchNormalization(epsilon=1e-9)(res_conv2_2)\n",
        "  res_add_2 = Add()([relu3, res_norm2_2])\n",
        "\n",
        "  # block_3\n",
        "  res_conv1_3 = Conv2D(256, 3, padding=\"same\")(res_add_2)\n",
        "  res_norm_3 = BatchNormalization(epsilon=1e-9)(res_conv1_3)\n",
        "  res_relu_3 = ReLU()(res_norm_3)\n",
        "  res_conv2_3 = Conv2D(256, 3, padding=\"same\")(res_relu_3)\n",
        "  res_norm2_3 = BatchNormalization(epsilon=1e-9)(res_conv2_3)\n",
        "  res_add_3 = Add()([relu3, res_norm2_3])\n",
        "\n",
        "  # block_4\n",
        "  res_conv1_4 = Conv2D(256, 3, padding=\"same\")(res_add_3)\n",
        "  res_norm_4 = BatchNormalization(epsilon=1e-9)(res_conv1_4)\n",
        "  res_relu_4 = ReLU()(res_norm_4)\n",
        "  res_conv2_4 = Conv2D(256, 3, padding=\"same\")(res_relu_4)\n",
        "  res_norm2_4 = BatchNormalization(epsilon=1e-9)(res_conv2_4)\n",
        "  res_add_4 = Add()([relu3, res_norm2_4])\n",
        "\n",
        "  # block_5\n",
        "  res_conv1_5 = Conv2D(256, 3, padding=\"same\")(res_add_4)\n",
        "  res_norm_5 = BatchNormalization(epsilon=1e-9)(res_conv1_5)\n",
        "  res_relu_5 = ReLU()(res_norm_5)\n",
        "  res_conv2_5 = Conv2D(256, 3, padding=\"same\")(res_relu_5)\n",
        "  res_norm2_5 = BatchNormalization(epsilon=1e-9)(res_conv2_5)\n",
        "  res_add_5 = Add()([relu3, res_norm2_5])\n",
        "\n",
        "  # block_6\n",
        "  res_conv1_6 = Conv2D(256, 3, padding=\"same\")(res_add_5)\n",
        "  res_norm_6 = BatchNormalization(epsilon=1e-9)(res_conv1_6)\n",
        "  res_relu_6 = ReLU()(res_norm_6)\n",
        "  res_conv2_6 = Conv2D(256, 3, padding=\"same\")(res_relu_6)\n",
        "  res_norm2_6 = BatchNormalization(epsilon=1e-9)(res_conv2_6)\n",
        "  res_add_6 = Add()([relu3, res_norm2_6])\n",
        "\n",
        "  # block_7\n",
        "  res_conv1_7 = Conv2D(256, 3, padding=\"same\")(res_add_6)\n",
        "  res_norm_7 = BatchNormalization(epsilon=1e-9)(res_conv1_7)\n",
        "  res_relu_7 = ReLU()(res_norm_7)\n",
        "  res_conv2_7 = Conv2D(256, 3, padding=\"same\")(res_relu_7)\n",
        "  res_norm2_7 = BatchNormalization(epsilon=1e-9)(res_conv2_7)\n",
        "  res_add_7 = Add()([relu3, res_norm2_7])\n",
        "\n",
        "  # block_8\n",
        "  res_conv1_8 = Conv2D(256, 3, padding=\"same\")(res_add_7)\n",
        "  res_norm_8 = BatchNormalization(epsilon=1e-9)(res_conv1_8)\n",
        "  res_relu_8 = ReLU()(res_norm_8)\n",
        "  res_conv2_8 = Conv2D(256, 3, padding=\"same\")(res_relu_8)\n",
        "  res_norm2_8 = BatchNormalization(epsilon=1e-9)(res_conv2_8)\n",
        "  res_add_8 = Add()([relu3, res_norm2_8])\n",
        "\n",
        "  # Up-convolution\n",
        "  upconv1 = Conv2DTranspose(128, 3, padding=\"same\", strides=(2, 2))(res_add_8)\n",
        "  upconv2 = Conv2D(128, 3, padding=\"same\")(upconv1)\n",
        "  upnorm1 = BatchNormalization(epsilon=1e-9)(upconv2)\n",
        "  uprelu1 = ReLU()(upnorm1)\n",
        "\n",
        "  upconv3 = Conv2DTranspose(64, 3, padding=\"same\", strides=(2, 2))(uprelu1)\n",
        "  upconv4 = Conv2D(64, 3, padding=\"same\")(upconv3)\n",
        "  upnorm2 = BatchNormalization(epsilon=1e-9)(upconv4)\n",
        "  uprelu2 = ReLU()(upnorm2)\n",
        "\n",
        "  out_ = Conv2D(3, 7, padding=\"same\")(uprelu2)\n",
        "  return Model(in_, out_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SYq3jyV9Xqm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def make_discriminator (use: discriminator = make_discriminator())\n",
        "\n",
        "def make_discriminator():\n",
        "  in_ = Input(shape=(256, 256, 3))\n",
        "  conv1 = Conv2D(32, 3, padding=\"same\")(in_)\n",
        "  relu1 = LeakyReLU(alpha=0.2)(conv1)\n",
        "\n",
        "  conv2 = Conv2D(64, 3, padding=\"same\", strides=(2, 2))(relu1)\n",
        "  relu2 = LeakyReLU(alpha=0.2)(conv2)\n",
        "  conv3 = Conv2D(128, 3, padding=\"same\")(relu2)\n",
        "  norm1 = BatchNormalization(epsilon=1e-9)(conv3)\n",
        "  relu3 = LeakyReLU(alpha=0.2)(norm1)\n",
        "\n",
        "  conv4 = Conv2D(128, 3, padding=\"same\", strides=(2, 2))(relu3)\n",
        "  relu4 = LeakyReLU(alpha=0.2)(conv4)\n",
        "  conv5 = Conv2D(256, 3, padding=\"same\")(relu4)\n",
        "  norm2 = BatchNormalization(epsilon=1e-9)(conv5)\n",
        "  relu5 = LeakyReLU(alpha=0.2)(norm2)\n",
        "\n",
        "  conv6 = Conv2D(256, 3, padding=\"same\")(relu5)\n",
        "  norm3 = BatchNormalization(epsilon=1e-9)(conv6)\n",
        "  relu6 = LeakyReLU(alpha=0.2)(norm3)\n",
        "  conv7 = Conv2D(1, 3, padding=\"same\")(relu6)\n",
        "  \n",
        "  flat = Flatten()(conv7)\n",
        "  \n",
        "  out_ = Dense(1, activation='softmax')(flat)\n",
        "  return Model(in_, out_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjMJoq0xKd_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "cellView": "form",
        "outputId": "31d322a0-b717-4c24-e017-6d8085f4db31"
      },
      "cell_type": "code",
      "source": [
        "#@title def make_vggModel\n",
        "def make_vggModel():\n",
        "  vgg = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "  return Model(vgg.input, vgg.get_layer('block4_conv4').output)\n",
        "\n",
        "vgg = make_vggModel()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_wiNp2rr6AIq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def vggLoss\n",
        "def vggLoss(a, b):\n",
        "  return K.sum(K.abs(vgg(a) - vgg(b)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDqyNVkXYi1Z",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def edgeLoss\n",
        "def edgeLoss(a, b):\n",
        "  return binary_crossentropy(a, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTX8_KWSUPnW",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title def cartoonGANLoss = vggLoss + edgeLoss\n",
        "def cartoonGANLoss(a, b):\n",
        "  omega = 10\n",
        "  return edgeLoss(a, b) + omega * vggLoss(a, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2RjScOyc5B9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def parseFramesFromVid #runs \n",
        "# def parseFramesFromVid(path):\n",
        "#   vidcap = cv2.VideoCapture(path)\n",
        "#   success,image = vidcap.read()\n",
        "#   count = 0\n",
        "#   while success:\n",
        "#     cv2.imwrite(\"keras_files/dataset/train/frame%d.jpg\" % count, image)\n",
        "#     success,image = vidcap.read()\n",
        "#     print(image.shape)\n",
        "#     count += 1\n",
        "\n",
        "# parseFramesFromVid('keras_files/tokyo.mp4') # this generates 6059 files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7jqPtJe7gB_U",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def getDataFromPath\n",
        "def getDataFromPath(path):\n",
        "  data = []\n",
        "  for (_, _, fnames) in os.walk(path):\n",
        "    for fname in fnames:\n",
        "      fpath = path + \"/\" + fname\n",
        "      im = cv2.imread(fpath)\n",
        "      data.append(im)\n",
        "  return np.asarray(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vCtKgdOMjWq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def getDataFromPathSingle (resizes and crops to center 256x256)\n",
        "def getDataFromPathSingle(paths):\n",
        "  data = []\n",
        "  for path in paths:\n",
        "    im = cv2.imread(path)\n",
        "    width = int(256/im.shape[0]*im.shape[1]) # calculate goal width, assuming width>height\n",
        "    im = cv2.resize(im, (width, 256)) # resize\n",
        "    crop_index = int(im.shape[1]/2 - 256/2) # crop index so width is 256\n",
        "    im = im[:, crop_index:crop_index+256] # crop\n",
        "    data.append(im)\n",
        "  return np.asarray(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xt0sbZZfA2sY",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title class CartoonGAN\n",
        "class CartoonGAN():\n",
        "  def __init__(self):\n",
        "    self.g = make_generator()\n",
        "    self.d = make_discriminator()\n",
        "  \n",
        "  def pretrainGenerator(self, data=None, epochs=5):\n",
        "    # goal of this step is to reconstruct image\n",
        "    path = 'keras_files/initializedGenerator.hdf5'\n",
        "    self.g.compile(loss=vggLoss, optimizer='adam') \n",
        "    \n",
        "    if os.path.isfile(path):\n",
        "      self.g.load_weights(path)\n",
        "    else:\n",
        "      self.g.fit(data, data, batch_size=16, epochs=epochs)\n",
        "      self.g.save_weights(path)\n",
        "  \n",
        "  def train(self, photos, anime, fuzzy, epochs=100):\n",
        "    self.g.compile(loss=cartoonGAN, optimizer='adam')\n",
        "    self.d.compile(loss=binary_crossentropy, optimizer='adam')\n",
        "    for i in range(100):\n",
        "       gen_anime = self.g.predict(photos)\n",
        "  \n",
        "  def generate(self, data):\n",
        "    pred = self.g.predict(data)\n",
        "    for i in range(pred.shape[0]):\n",
        "      im_array = pred[i]\n",
        "      im = Image.fromarray((im_array * 255 / np.max(im_array)).astype('uint8'))\n",
        "      im.save('keras_files/sample_out/' + str(i) + '.jpg')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1n9dzk5-opUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = getDataFromPath('keras_files/dataset/train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Rj7fh93M5FM",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1166
        },
        "outputId": "cc3ef859-5135-4e21-85d9-de599b988c27"
      },
      "cell_type": "code",
      "source": [
        "#@title create GAN and run initializer\n",
        "gan = CartoonGAN()\n",
        "gan.pretrainGenerator(data=data, epochs=20)\n",
        "# gan.pretrainGenerator()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2784/6059 [============>.................] - ETA: 9:29 - loss: 340389038.8966"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-bdf1b4894f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCartoonGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrainGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphotos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphotos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# gan.pretrainGenerator()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-17d169043b31>\u001b[0m in \u001b[0;36mpretrainGenerator\u001b[0;34m(self, photos, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphotos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphotos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,512,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_4/Adam/gradients/loss_14/conv2d_303_loss/Abs_grad/mul-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pIcqO1fQDiGv",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title test generate\n",
        "testdata = getDataFromPathSingle(['keras_files/dataset/train/frame1545.jpg', 'keras_files/dataset/train/frame1546.jpg'])\n",
        "gan.generate(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "No0connTWxQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title train GAN\n",
        "gan.train()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}