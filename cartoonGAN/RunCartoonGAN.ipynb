{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RunCartoonGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julinas/202-project3/blob/scene/cartoonGAN/RunCartoonGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Mkl_CrK731pf",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "27fca37f-1e92-453f-e307-8ee29e2715dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "#@title mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-Pjvgu2a5xi",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "b9743e3f-a105-404e-a5e4-194851ade945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#@title cd to project3 folder\n",
        "%cd 'drive/My Drive/Colab Notebooks/project3'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/project3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1hvdynmmDmm3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title pytorch version run test\n",
        "# import torch\n",
        "# !python test.py --input_dir \"../sample\" --output_dir \"../sample_out\" --style Hosoda --gpu 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLm5_WJReeUV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title imports \n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Reshape, Input, Conv2D, Conv2DTranspose, MaxPooling2D, Dense, BatchNormalization, ReLU, Add, LeakyReLU\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "from keras import Model\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eAjxWGnSegps",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "125bca18-b6d0-4186-e1c5-7156f5892ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "#@title def make_generator; runs\n",
        "\n",
        "def make_generator():\n",
        "  in_ = Input(shape=(256, 256, 3))\n",
        "  conv1 = Conv2D(64, 7, padding=\"same\")(in_)\n",
        "  norm1 = BatchNormalization(epsilon=1e-9)(conv1)\n",
        "  relu1 = ReLU()(norm1)\n",
        "\n",
        "  # Down-convolution\n",
        "  conv2 = Conv2D(128, 3, padding=\"same\", strides=(2, 2))(relu1)\n",
        "  conv3 = Conv2D(128, 3, padding=\"same\")(conv2)\n",
        "  norm2 = BatchNormalization(epsilon=1e-9)(conv3)\n",
        "  relu2 = ReLU()(norm2)\n",
        "\n",
        "  conv4 = Conv2D(256, 3, padding=\"same\", strides=(2, 2))(relu2)\n",
        "  conv5 = Conv2D(256, 3, padding=\"same\")(conv4)\n",
        "  norm3 = BatchNormalization(epsilon=1e-9)(conv5)\n",
        "  relu3 = ReLU()(norm3)\n",
        "\n",
        "  # 8 residual blocks\n",
        "  # block_1\n",
        "  res_conv1_1 = Conv2D(256, 3, padding=\"same\")(relu3)\n",
        "  res_norm_1 = BatchNormalization(epsilon=1e-9)(res_conv1_1)\n",
        "  res_relu_1 = ReLU()(res_norm_1)\n",
        "  res_conv2_1 = Conv2D(256, 3, padding=\"same\")(res_relu_1)\n",
        "  res_norm2_1 = BatchNormalization(epsilon=1e-9)(res_conv2_1)\n",
        "  res_add_1 = Add()([relu3, res_norm2_1])\n",
        "\n",
        "  # block_2\n",
        "  res_conv1_2 = Conv2D(256, 3, padding=\"same\")(res_add_1)\n",
        "  res_norm_2 = BatchNormalization(epsilon=1e-9)(res_conv1_2)\n",
        "  res_relu_2 = ReLU()(res_norm_2)\n",
        "  res_conv2_2 = Conv2D(256, 3, padding=\"same\")(res_relu_2)\n",
        "  res_norm2_2 = BatchNormalization(epsilon=1e-9)(res_conv2_2)\n",
        "  res_add_2 = Add()([relu3, res_norm2_2])\n",
        "\n",
        "  # block_3\n",
        "  res_conv1_3 = Conv2D(256, 3, padding=\"same\")(res_add_2)\n",
        "  res_norm_3 = BatchNormalization(epsilon=1e-9)(res_conv1_3)\n",
        "  res_relu_3 = ReLU()(res_norm_3)\n",
        "  res_conv2_3 = Conv2D(256, 3, padding=\"same\")(res_relu_3)\n",
        "  res_norm2_3 = BatchNormalization(epsilon=1e-9)(res_conv2_3)\n",
        "  res_add_3 = Add()([relu3, res_norm2_3])\n",
        "\n",
        "  # block_4\n",
        "  res_conv1_4 = Conv2D(256, 3, padding=\"same\")(res_add_3)\n",
        "  res_norm_4 = BatchNormalization(epsilon=1e-9)(res_conv1_4)\n",
        "  res_relu_4 = ReLU()(res_norm_4)\n",
        "  res_conv2_4 = Conv2D(256, 3, padding=\"same\")(res_relu_4)\n",
        "  res_norm2_4 = BatchNormalization(epsilon=1e-9)(res_conv2_4)\n",
        "  res_add_4 = Add()([relu3, res_norm2_4])\n",
        "\n",
        "  # block_5\n",
        "  res_conv1_5 = Conv2D(256, 3, padding=\"same\")(res_add_4)\n",
        "  res_norm_5 = BatchNormalization(epsilon=1e-9)(res_conv1_5)\n",
        "  res_relu_5 = ReLU()(res_norm_5)\n",
        "  res_conv2_5 = Conv2D(256, 3, padding=\"same\")(res_relu_5)\n",
        "  res_norm2_5 = BatchNormalization(epsilon=1e-9)(res_conv2_5)\n",
        "  res_add_5 = Add()([relu3, res_norm2_5])\n",
        "\n",
        "  # block_6\n",
        "  res_conv1_6 = Conv2D(256, 3, padding=\"same\")(res_add_5)\n",
        "  res_norm_6 = BatchNormalization(epsilon=1e-9)(res_conv1_6)\n",
        "  res_relu_6 = ReLU()(res_norm_6)\n",
        "  res_conv2_6 = Conv2D(256, 3, padding=\"same\")(res_relu_6)\n",
        "  res_norm2_6 = BatchNormalization(epsilon=1e-9)(res_conv2_6)\n",
        "  res_add_6 = Add()([relu3, res_norm2_6])\n",
        "\n",
        "  # block_7\n",
        "  res_conv1_7 = Conv2D(256, 3, padding=\"same\")(res_add_6)\n",
        "  res_norm_7 = BatchNormalization(epsilon=1e-9)(res_conv1_7)\n",
        "  res_relu_7 = ReLU()(res_norm_7)\n",
        "  res_conv2_7 = Conv2D(256, 3, padding=\"same\")(res_relu_7)\n",
        "  res_norm2_7 = BatchNormalization(epsilon=1e-9)(res_conv2_7)\n",
        "  res_add_7 = Add()([relu3, res_norm2_7])\n",
        "\n",
        "  # block_8\n",
        "  res_conv1_8 = Conv2D(256, 3, padding=\"same\")(res_add_7)\n",
        "  res_norm_8 = BatchNormalization(epsilon=1e-9)(res_conv1_8)\n",
        "  res_relu_8 = ReLU()(res_norm_8)\n",
        "  res_conv2_8 = Conv2D(256, 3, padding=\"same\")(res_relu_8)\n",
        "  res_norm2_8 = BatchNormalization(epsilon=1e-9)(res_conv2_8)\n",
        "  res_add_8 = Add()([relu3, res_norm2_8])\n",
        "\n",
        "  # Up-convolution\n",
        "  upconv1 = Conv2DTranspose(128, 3, padding=\"same\", strides=(2, 2))(res_add_8)\n",
        "  upconv2 = Conv2D(128, 3, padding=\"same\")(upconv1)\n",
        "  upnorm1 = BatchNormalization(epsilon=1e-9)(upconv2)\n",
        "  uprelu1 = ReLU()(upnorm1)\n",
        "\n",
        "  upconv3 = Conv2DTranspose(64, 3, padding=\"same\", strides=(2, 2))(uprelu1)\n",
        "  upconv4 = Conv2D(64, 3, padding=\"same\")(upconv3)\n",
        "  upnorm2 = BatchNormalization(epsilon=1e-9)(upconv4)\n",
        "  uprelu2 = ReLU()(upnorm2)\n",
        "\n",
        "  out_ = Conv2D(3, 7, padding=\"same\")(uprelu2)\n",
        "  return Model(in_, out_)\n",
        "\n",
        "generator = make_generator()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2SYq3jyV9Xqm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def make_discriminator; runs\n",
        "\n",
        "def make_discriminator():\n",
        "  in_ = Input(shape=(256, 256, 3))\n",
        "  conv1 = Conv2D(32, 3, padding=\"same\")(in_)\n",
        "  relu1 = LeakyReLU(alpha=0.2)(conv1)\n",
        "\n",
        "  conv2 = Conv2D(64, 3, padding=\"same\", strides=(2, 2))(relu1)\n",
        "  relu2 = LeakyReLU(alpha=0.2)(conv2)\n",
        "  conv3 = Conv2D(128, 3, padding=\"same\")(relu2)\n",
        "  norm1 = BatchNormalization(epsilon=1e-9)(conv3)\n",
        "  relu3 = LeakyReLU(alpha=0.2)(norm1)\n",
        "\n",
        "  conv4 = Conv2D(128, 3, padding=\"same\", strides=(2, 2))(relu3)\n",
        "  relu4 = LeakyReLU(alpha=0.2)(conv4)\n",
        "  conv5 = Conv2D(256, 3, padding=\"same\")(relu4)\n",
        "  norm2 = BatchNormalization(epsilon=1e-9)(conv5)\n",
        "  relu5 = LeakyReLU(alpha=0.2)(norm2)\n",
        "\n",
        "  conv6 = Conv2D(256, 3, padding=\"same\")(relu5)\n",
        "  norm3 = BatchNormalization(epsilon=1e-9)(conv6)\n",
        "  relu6 = LeakyReLU(alpha=0.2)(norm3)\n",
        "  conv7 = Conv2D(1, 3, padding=\"same\")(relu6)\n",
        "  \n",
        "  flat = Reshape((4096,))(conv7)\n",
        "  \n",
        "  out_ = Dense(1, activation='softmax')(flat)\n",
        "  return Model(in_, out_)\n",
        "\n",
        "discriminator = make_discriminator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjMJoq0xKd_6",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "afd7de6b-376b-4dd8-e775-ad2fab451a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "#@title def make_vggModel; runs\n",
        "def make_vggModel():\n",
        "  vgg = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "  return Model(vgg.input, vgg.get_layer('block4_conv4').output)\n",
        "\n",
        "vgg = make_vggModel()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_wiNp2rr6AIq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def vggLoss\n",
        "def vggLoss(y_pred, y_true):\n",
        "  return K.sum(K.abs(vgg(y_pred) - vgg(y_true)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDqyNVkXYi1Z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def edgeLoss\n",
        "def edgeLoss(y_pred, y_true):\n",
        "  return K.log(1 - discriminator(y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTX8_KWSUPnW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def cartoonGANLoss = edgeLoss + omega * vggLoss\n",
        "def cartoonGANLoss(y_pred, y_true):\n",
        "  omega = 10\n",
        "  loss1 = edgeLoss(y_pred, y_true)\n",
        "  loss2 = omega * vggLoss(y_pred, y_true)\n",
        "  return loss1 + loss2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7jqPtJe7gB_U",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def getDataFromPath\n",
        "def getDataFromPath(path):\n",
        "  data = []\n",
        "  for (_, _, fnames) in os.walk(path):\n",
        "    for i in range(2000):\n",
        "      fname = fnames[i]\n",
        "      fpath = path + \"/\" + fname\n",
        "      im = cv2.imread(fpath)\n",
        "      data.append(im)\n",
        "  return np.asarray(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vCtKgdOMjWq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def getDataFromPathIndividual (resizes and crops to center 256x256)\n",
        "def getDataFromPathIndividual(paths):\n",
        "  data = []\n",
        "  for path in paths:\n",
        "    im = cv2.imread(path)\n",
        "    width = int(256/im.shape[0]*im.shape[1]) # calculate goal width, assuming width>height\n",
        "    im = cv2.resize(im, (width, 256)) # resize\n",
        "    crop_index = int(im.shape[1]/2 - 256/2) # crop index so width is 256\n",
        "    im = im[:, crop_index:crop_index+256] # crop\n",
        "    data.append(im)\n",
        "  return np.asarray(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xt0sbZZfA2sY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title class CartoonGAN\n",
        "class CartoonGAN():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def pretrainGenerator(self, datapath=None, epochs=5):\n",
        "    # goal of this step is to reconstruct image\n",
        "    path = 'keras_files/initializedGenerator.hdf5'\n",
        "    generator.compile(loss=vggLoss, optimizer='adam') \n",
        "    \n",
        "    if os.path.isfile(path):\n",
        "      generator.load_weights(path)\n",
        "    elif os.path.isdir(datapath) is False:\n",
        "      print(\"Pretraining data path is not provided. Did not pretrain.\")\n",
        "    else:\n",
        "      data = getDataFromPath(datapath)\n",
        "      print(\"Training on data shaped {}.\".format(data.shape))\n",
        "      generator.fit(data, data, batch_size=16, epochs=epochs)\n",
        "      generator.save_weights(path)\n",
        "  \n",
        "  def train(self, photos, anime, fuzzy, epochs=100, test_image=None):\n",
        "    path = 'keras_files/checkpoints/'\n",
        "    generator.compile(loss=cartoonGANLoss, optimizer='adam')\n",
        "    discriminator.compile(loss=binary_crossentropy, optimizer='adam')\n",
        "    \n",
        "    data = np.concatenate((anime, fuzzy))\n",
        "    \n",
        "    anime_y_true = np.ones((len(anime),))\n",
        "    fuzzy_y_true = np.zeros((len(fuzzy),))\n",
        "    gen_anime_y_true = np.zeros((len(photos),))\n",
        "    y_true = np.concatenate((anime_y_true, fuzzy_y_true))\n",
        "    y_true = np.concatenate((y_true, gen_anime_y_true))\n",
        "    \n",
        "    for i in range(epochs):\n",
        "      # train discriminator\n",
        "      gen_anime = generator.predict(photos)\n",
        "      this_data = np.concatenate((data, gen_anime))\n",
        "      discriminator.fit(this_data, y_true, validation_split=0.2, batch_size=16, epochs=1)\n",
        "      \n",
        "      # train generator\n",
        "      generator.fit(photos, photos, validation_split=0.2, batch_size=16, epochs=1)\n",
        "      \n",
        "      if test_image is not None:\n",
        "        self.generate(test_image, 'epoch' + str(i) + '.jpg')\n",
        "      generator.save_weights(path + 'generator' + str(i) + \".hdf5\")\n",
        "      discriminator.save_weights(path + 'discriminator' + str(i) + \".hdf5\")\n",
        "  \n",
        "  def generate(self, data, output_name=None):\n",
        "    pred = generator.predict(data)\n",
        "    for i in range(pred.shape[0]):\n",
        "      im_array = pred[i]\n",
        "      im = Image.fromarray((im_array * 255 / np.max(im_array)).astype('uint8'))\n",
        "      if output_name is not None:\n",
        "        im.save('keras_files/sample_out/' + output_name)\n",
        "      else:\n",
        "        im.save('keras_files/sample_out/' + str(i) + '.jpg')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Rj7fh93M5FM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title create GAN and run initializer\n",
        "gan = CartoonGAN()\n",
        "gan.pretrainGenerator(datapath='keras_files/dataset/flickr_train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJHuPYGtPpc2",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title get test data for training\n",
        "testdata = getDataFromPathIndividual(['keras_files/dataset/flickr_train256x256/1820795682.jpg'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zaWssNDlOkM3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title load training data photos\n",
        "photos = getDataFromPath('keras_files/dataset/flickr_train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgJUebmBRDJ5",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title load training data anime\n",
        "anime = getDataFromPath('keras_files/dataset/sailor_moon_train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2dQ-b8GRDWQ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title load training data fuzzy\n",
        "fuzzy = getDataFromPath('keras_files/dataset/sailor_moon_fuzzy_train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "No0connTWxQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title train GAN\n",
        "gan.train(photos, anime, fuzzy, test_image=testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}