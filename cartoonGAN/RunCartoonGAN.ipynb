{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RunCartoonGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julinas/202-project3/blob/scene/cartoonGAN/RunCartoonGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Mkl_CrK731pf",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "14903079-e2cc-4636-8507-0f1dffa7a799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "#@title mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-Pjvgu2a5xi",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "718ee301-e373-4624-f455-cfe2d647cea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#@title cd to project3 folder\n",
        "%cd 'drive/My Drive/Colab Notebooks/project3'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/project3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1hvdynmmDmm3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title pytorch version run test\n",
        "# import torch\n",
        "# !python test.py --input_dir \"../sample\" --output_dir \"../sample_out\" --style Hosoda --gpu 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLm5_WJReeUV",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "af13bb3a-4edf-4a13-d623-6174b7174d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#@title imports \n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Reshape, Input, Conv2D, Conv2DTranspose, MaxPooling2D, Dense, BatchNormalization, ReLU, Add, LeakyReLU\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "from keras import Model\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eAjxWGnSegps",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "caed3997-bc22-4516-f959-adb9f3619f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "#@title def make_generator; runs\n",
        "\n",
        "def make_generator():\n",
        "  in_ = Input(shape=(256, 256, 3))\n",
        "  conv1 = Conv2D(64, 7, padding=\"same\")(in_)\n",
        "  norm1 = BatchNormalization(epsilon=1e-9)(conv1)\n",
        "  relu1 = ReLU()(norm1)\n",
        "\n",
        "  # Down-convolution\n",
        "  conv2 = Conv2D(128, 3, padding=\"same\", strides=(2, 2))(relu1)\n",
        "  conv3 = Conv2D(128, 3, padding=\"same\")(conv2)\n",
        "  norm2 = BatchNormalization(epsilon=1e-9)(conv3)\n",
        "  relu2 = ReLU()(norm2)\n",
        "\n",
        "  conv4 = Conv2D(256, 3, padding=\"same\", strides=(2, 2))(relu2)\n",
        "  conv5 = Conv2D(256, 3, padding=\"same\")(conv4)\n",
        "  norm3 = BatchNormalization(epsilon=1e-9)(conv5)\n",
        "  relu3 = ReLU()(norm3)\n",
        "\n",
        "  # 8 residual blocks\n",
        "  # block_1\n",
        "  res_conv1_1 = Conv2D(256, 3, padding=\"same\")(relu3)\n",
        "  res_norm_1 = BatchNormalization(epsilon=1e-9)(res_conv1_1)\n",
        "  res_relu_1 = ReLU()(res_norm_1)\n",
        "  res_conv2_1 = Conv2D(256, 3, padding=\"same\")(res_relu_1)\n",
        "  res_norm2_1 = BatchNormalization(epsilon=1e-9)(res_conv2_1)\n",
        "  res_add_1 = Add()([relu3, res_norm2_1])\n",
        "\n",
        "  # block_2\n",
        "  res_conv1_2 = Conv2D(256, 3, padding=\"same\")(res_add_1)\n",
        "  res_norm_2 = BatchNormalization(epsilon=1e-9)(res_conv1_2)\n",
        "  res_relu_2 = ReLU()(res_norm_2)\n",
        "  res_conv2_2 = Conv2D(256, 3, padding=\"same\")(res_relu_2)\n",
        "  res_norm2_2 = BatchNormalization(epsilon=1e-9)(res_conv2_2)\n",
        "  res_add_2 = Add()([relu3, res_norm2_2])\n",
        "\n",
        "  # block_3\n",
        "  res_conv1_3 = Conv2D(256, 3, padding=\"same\")(res_add_2)\n",
        "  res_norm_3 = BatchNormalization(epsilon=1e-9)(res_conv1_3)\n",
        "  res_relu_3 = ReLU()(res_norm_3)\n",
        "  res_conv2_3 = Conv2D(256, 3, padding=\"same\")(res_relu_3)\n",
        "  res_norm2_3 = BatchNormalization(epsilon=1e-9)(res_conv2_3)\n",
        "  res_add_3 = Add()([relu3, res_norm2_3])\n",
        "\n",
        "  # block_4\n",
        "  res_conv1_4 = Conv2D(256, 3, padding=\"same\")(res_add_3)\n",
        "  res_norm_4 = BatchNormalization(epsilon=1e-9)(res_conv1_4)\n",
        "  res_relu_4 = ReLU()(res_norm_4)\n",
        "  res_conv2_4 = Conv2D(256, 3, padding=\"same\")(res_relu_4)\n",
        "  res_norm2_4 = BatchNormalization(epsilon=1e-9)(res_conv2_4)\n",
        "  res_add_4 = Add()([relu3, res_norm2_4])\n",
        "\n",
        "  # block_5\n",
        "  res_conv1_5 = Conv2D(256, 3, padding=\"same\")(res_add_4)\n",
        "  res_norm_5 = BatchNormalization(epsilon=1e-9)(res_conv1_5)\n",
        "  res_relu_5 = ReLU()(res_norm_5)\n",
        "  res_conv2_5 = Conv2D(256, 3, padding=\"same\")(res_relu_5)\n",
        "  res_norm2_5 = BatchNormalization(epsilon=1e-9)(res_conv2_5)\n",
        "  res_add_5 = Add()([relu3, res_norm2_5])\n",
        "\n",
        "  # block_6\n",
        "  res_conv1_6 = Conv2D(256, 3, padding=\"same\")(res_add_5)\n",
        "  res_norm_6 = BatchNormalization(epsilon=1e-9)(res_conv1_6)\n",
        "  res_relu_6 = ReLU()(res_norm_6)\n",
        "  res_conv2_6 = Conv2D(256, 3, padding=\"same\")(res_relu_6)\n",
        "  res_norm2_6 = BatchNormalization(epsilon=1e-9)(res_conv2_6)\n",
        "  res_add_6 = Add()([relu3, res_norm2_6])\n",
        "\n",
        "  # block_7\n",
        "  res_conv1_7 = Conv2D(256, 3, padding=\"same\")(res_add_6)\n",
        "  res_norm_7 = BatchNormalization(epsilon=1e-9)(res_conv1_7)\n",
        "  res_relu_7 = ReLU()(res_norm_7)\n",
        "  res_conv2_7 = Conv2D(256, 3, padding=\"same\")(res_relu_7)\n",
        "  res_norm2_7 = BatchNormalization(epsilon=1e-9)(res_conv2_7)\n",
        "  res_add_7 = Add()([relu3, res_norm2_7])\n",
        "\n",
        "  # block_8\n",
        "  res_conv1_8 = Conv2D(256, 3, padding=\"same\")(res_add_7)\n",
        "  res_norm_8 = BatchNormalization(epsilon=1e-9)(res_conv1_8)\n",
        "  res_relu_8 = ReLU()(res_norm_8)\n",
        "  res_conv2_8 = Conv2D(256, 3, padding=\"same\")(res_relu_8)\n",
        "  res_norm2_8 = BatchNormalization(epsilon=1e-9)(res_conv2_8)\n",
        "  res_add_8 = Add()([relu3, res_norm2_8])\n",
        "\n",
        "  # Up-convolution\n",
        "  upconv1 = Conv2DTranspose(128, 3, padding=\"same\", strides=(2, 2))(res_add_8)\n",
        "  upconv2 = Conv2D(128, 3, padding=\"same\")(upconv1)\n",
        "  upnorm1 = BatchNormalization(epsilon=1e-9)(upconv2)\n",
        "  uprelu1 = ReLU()(upnorm1)\n",
        "\n",
        "  upconv3 = Conv2DTranspose(64, 3, padding=\"same\", strides=(2, 2))(uprelu1)\n",
        "  upconv4 = Conv2D(64, 3, padding=\"same\")(upconv3)\n",
        "  upnorm2 = BatchNormalization(epsilon=1e-9)(upconv4)\n",
        "  uprelu2 = ReLU()(upnorm2)\n",
        "\n",
        "  out_ = Conv2D(3, 7, padding=\"same\")(uprelu2)\n",
        "  return Model(in_, out_)\n",
        "\n",
        "generator = make_generator()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2SYq3jyV9Xqm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def make_discriminator; runs\n",
        "\n",
        "def make_discriminator():\n",
        "  in_ = Input(shape=(256, 256, 3))\n",
        "  conv1 = Conv2D(32, 3, padding=\"same\")(in_)\n",
        "  relu1 = LeakyReLU(alpha=0.2)(conv1)\n",
        "\n",
        "  conv2 = Conv2D(64, 3, padding=\"same\", strides=(2, 2))(relu1)\n",
        "  relu2 = LeakyReLU(alpha=0.2)(conv2)\n",
        "  conv3 = Conv2D(128, 3, padding=\"same\")(relu2)\n",
        "  norm1 = BatchNormalization(epsilon=1e-9)(conv3)\n",
        "  relu3 = LeakyReLU(alpha=0.2)(norm1)\n",
        "\n",
        "  conv4 = Conv2D(128, 3, padding=\"same\", strides=(2, 2))(relu3)\n",
        "  relu4 = LeakyReLU(alpha=0.2)(conv4)\n",
        "  conv5 = Conv2D(256, 3, padding=\"same\")(relu4)\n",
        "  norm2 = BatchNormalization(epsilon=1e-9)(conv5)\n",
        "  relu5 = LeakyReLU(alpha=0.2)(norm2)\n",
        "\n",
        "  conv6 = Conv2D(256, 3, padding=\"same\")(relu5)\n",
        "  norm3 = BatchNormalization(epsilon=1e-9)(conv6)\n",
        "  relu6 = LeakyReLU(alpha=0.2)(norm3)\n",
        "  conv7 = Conv2D(1, 3, padding=\"same\")(relu6)\n",
        "  \n",
        "  flat = Reshape((4096,))(conv7)\n",
        "  \n",
        "  out_ = Dense(1, activation='softmax')(flat)\n",
        "  return Model(in_, out_)\n",
        "\n",
        "discriminator = make_discriminator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjMJoq0xKd_6",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "c27dff89-10c6-451d-f1bb-96b94f64a568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "#@title def make_vggModel; runs\n",
        "def make_vggModel():\n",
        "  vgg = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "  return Model(vgg.input, vgg.get_layer('block4_conv4').output)\n",
        "\n",
        "vgg = make_vggModel()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_wiNp2rr6AIq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def vggLoss\n",
        "def vggLoss(y_pred, y_true):\n",
        "  return K.sum(K.abs(vgg(y_pred) - vgg(y_true)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDqyNVkXYi1Z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def edgeLoss\n",
        "def edgeLoss(y_pred, y_true):\n",
        "  return K.log(1 - discriminator(y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTX8_KWSUPnW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def cartoonGANLoss = edgeLoss + 10 * vggLoss\n",
        "def cartoonGANLoss(y_pred, y_true):\n",
        "  loss1 = 0.1 * edgeLoss(y_pred, y_true)\n",
        "  loss2 = vggLoss(y_pred, y_true)\n",
        "  return 0.0000001 * (loss1 + loss2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7jqPtJe7gB_U",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def getDataFromPath\n",
        "def getDataFromPath(path):\n",
        "  data = []\n",
        "  for (_, _, fnames) in os.walk(path):\n",
        "    for i in range(100):\n",
        "      fname = fnames[i]\n",
        "      fpath = path + \"/\" + fname\n",
        "      im = cv2.imread(fpath)\n",
        "      data.append(im)\n",
        "  return np.asarray(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vCtKgdOMjWq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title def getDataFromPathIndividual (resizes and crops to center 256x256)\n",
        "def getDataFromPathIndividual(paths):\n",
        "  data = []\n",
        "  for path in paths:\n",
        "    im = cv2.imread(path)\n",
        "    width = int(256/im.shape[0]*im.shape[1]) # calculate goal width, assuming width>height\n",
        "    im = cv2.resize(im, (width, 256)) # resize\n",
        "    crop_index = int(im.shape[1]/2 - 256/2) # crop index so width is 256\n",
        "    im = im[:, crop_index:crop_index+256] # crop\n",
        "    data.append(im)\n",
        "  return np.asarray(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xt0sbZZfA2sY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title class CartoonGAN\n",
        "class CartoonGAN():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def pretrainGenerator(self, datapath=None, epochs=20):\n",
        "    # goal of this step is to reconstruct image\n",
        "    path = 'keras_files/initializedGenerator_20.hdf5'\n",
        "    generator.compile(loss=vggLoss, optimizer='adam') \n",
        "    \n",
        "    if os.path.isfile(path):\n",
        "      generator.load_weights(path)\n",
        "    elif os.path.isdir(datapath) is False:\n",
        "      print(\"Pretraining data path is not provided. Did not pretrain.\")\n",
        "    else:\n",
        "      data = getDataFromPath(datapath)\n",
        "      print(\"Training on data shaped {}.\".format(data.shape))\n",
        "      generator.fit(data, data, batch_size=16, epochs=epochs)\n",
        "      generator.save_weights(path)\n",
        "  \n",
        "  def train(self, photos, anime, fuzzy, epochs=100, test_image=None):\n",
        "    path = 'keras_files/checkpoints/'\n",
        "    adam_g = Adam(lr=0.00000001)\n",
        "    generator.compile(loss=cartoonGANLoss, optimizer=adam_g)\n",
        "    discriminator.compile(loss=binary_crossentropy, optimizer='adam')\n",
        "    \n",
        "    data = np.concatenate((anime, fuzzy))\n",
        "    \n",
        "    anime_y_true = np.ones((len(anime),))\n",
        "    fuzzy_y_true = np.zeros((len(fuzzy),))\n",
        "    gen_anime_y_true = np.zeros((len(photos),))\n",
        "    y_true = np.concatenate((anime_y_true, fuzzy_y_true))\n",
        "    y_true = np.concatenate((y_true, gen_anime_y_true))\n",
        "    \n",
        "    for i in range(epochs):\n",
        "      # train discriminator\n",
        "      gen_anime = generator.predict(photos)\n",
        "      this_data = np.concatenate((data, gen_anime))\n",
        "      discriminator.fit(this_data, y_true, validation_split=0.2, batch_size=16, epochs=1)\n",
        "      \n",
        "      # train generator\n",
        "      generator.fit(photos, photos, validation_split=0.2, batch_size=16, epochs=1)\n",
        "      \n",
        "      if test_image is not None:\n",
        "        self.generate(test_image, 'epoch' + str(i) + '.jpg')\n",
        "      generator.save_weights(path + 'generator' + str(i) + \".hdf5\")\n",
        "      discriminator.save_weights(path + 'discriminator' + str(i) + \".hdf5\")\n",
        "  \n",
        "  def generate(self, data, output_name=None):\n",
        "    pred = generator.predict(data)\n",
        "    for i in range(pred.shape[0]):\n",
        "      im_array = pred[i]\n",
        "      im = Image.fromarray((im_array * 255 / np.max(im_array)).astype('uint8'))\n",
        "      if output_name is not None:\n",
        "        im.save('keras_files/sample_out/' + output_name)\n",
        "      else:\n",
        "        im.save('keras_files/sample_out/' + str(i) + '.jpg')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Rj7fh93M5FM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1148
        },
        "outputId": "daab6362-4264-4429-b387-91197108f0d0"
      },
      "cell_type": "code",
      "source": [
        "#@title create GAN and run initializer\n",
        "gan = CartoonGAN()\n",
        "gan.pretrainGenerator(datapath='keras_files/dataset/flickr_train256x256')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on data shaped (100, 256, 256, 3).\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 32s 315ms/step - loss: 452108648.0000\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 449874354.8800\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 448640952.3200\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 451286102.7200\n",
            "Epoch 5/20\n",
            " 64/100 [==================>...........] - ETA: 5s - loss: 490356632.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9166626235df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCartoonGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrainGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'keras_files/dataset/flickr_train256x256'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-1f2e6599e529>\u001b[0m in \u001b[0;36mpretrainGenerator\u001b[0;34m(self, datapath, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDataFromPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on data shaped {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PJHuPYGtPpc2",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title get test data for training\n",
        "testdata = getDataFromPathIndividual(['keras_files/dataset/flickr_train256x256/1820795682.jpg'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zaWssNDlOkM3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title load training data photos\n",
        "photos = getDataFromPath('keras_files/dataset/flickr_train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgJUebmBRDJ5",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title load training data anime\n",
        "anime = getDataFromPath('keras_files/dataset/sailor_moon_train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2dQ-b8GRDWQ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title load training data fuzzy\n",
        "fuzzy = getDataFromPath('keras_files/dataset/sailor_moon_fuzzy_train256x256')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "No0connTWxQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "68f00992-06ec-42f5-efb7-5c1b1e817127"
      },
      "cell_type": "code",
      "source": [
        "#@title train GAN\n",
        "gan.train(photos, anime, fuzzy, test_image=testdata)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-273959d628f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphotos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuzzy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gan' is not defined"
          ]
        }
      ]
    }
  ]
}